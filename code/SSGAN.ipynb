{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SSGAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ4tt57zYkhs"
      },
      "source": [
        "\n",
        "# MNIST functional API\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg2YCZDmXzxr"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxBXZXk3X5oW"
      },
      "source": [
        "inputs = keras.Input(shape=(784,))\n",
        "dense = layers.Dense(64, activation=\"relu\")\n",
        "x = dense(inputs)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(10)(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW71p89iYFmY",
        "outputId": "3b32e601-2871-4efc-fc0e-8525d111548b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mnist_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,050\n",
            "Trainable params: 55,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY92bL0yYGfV",
        "outputId": "deff8fcf-86d5-416f-e7de-dc9e56e60b7f"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
        "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D97vROHpYR-d",
        "outputId": "11123384-369e-462c-ed17-f1e94ea8fb31"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_split=0.2)\n",
        "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"Test loss:\", test_scores[0])\n",
        "print(\"Test accuracy:\", test_scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "750/750 [==============================] - 4s 4ms/step - loss: 0.3414 - accuracy: 0.9024 - val_loss: 0.1930 - val_accuracy: 0.9419\n",
            "Epoch 2/2\n",
            "750/750 [==============================] - 3s 3ms/step - loss: 0.1645 - accuracy: 0.9505 - val_loss: 0.1389 - val_accuracy: 0.9590\n",
            "313/313 - 0s - loss: 0.1358 - accuracy: 0.9593 - 365ms/epoch - 1ms/step\n",
            "Test loss: 0.1358363926410675\n",
            "Test accuracy: 0.9592999815940857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaXzjqVYYeph"
      },
      "source": [
        "# Multiple Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_039px6ZCpb",
        "outputId": "e551c6f9-471f-45c1-bc58-9b86852aba49"
      },
      "source": [
        "encoder_input = keras.Input(shape=(28, 28, 1), name=\"original_img\")\n",
        "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(3)(x)\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
        "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
        "encoder.summary()\n",
        "\n",
        "decoder_input = keras.Input(shape=(16,), name=\"encoded_img\")\n",
        "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
        "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
        "x = layers.UpSampling2D(3)(x)\n",
        "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
        "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
        "\n",
        "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "decoder.summary()\n",
        "\n",
        "autoencoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
        "encoded_img = encoder(autoencoder_input)\n",
        "decoded_img = decoder(encoded_img)\n",
        "autoencoder = keras.Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " original_img (InputLayer)   [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 24, 24, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 6, 6, 32)          9248      \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 16)          4624      \n",
            "                                                                 \n",
            " global_max_pooling2d_1 (Glo  (None, 16)               0         \n",
            " balMaxPooling2D)                                                \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,672\n",
            "Trainable params: 18,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoded_img (InputLayer)    [(None, 16)]              0         \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 4, 4, 1)           0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 6, 6, 16)         160       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 8, 8, 32)         4640      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSampling  (None, 24, 24, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_transpose_6 (Conv2DT  (None, 26, 26, 16)       4624      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_7 (Conv2DT  (None, 28, 28, 1)        145       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,569\n",
            "Trainable params: 9,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " img (InputLayer)            [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " encoder (Functional)        (None, 16)                18672     \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 28, 28, 1)         9569      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,241\n",
            "Trainable params: 28,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JQ7XvvtfcEM"
      },
      "source": [
        "# Implementation SSGAN \n",
        "* https://github.com/KunalVaidya99/Semi-Supervised-GAN/blob/master/Semi_Supervised_GAN.ipynb\n",
        "* https://towardsdatascience.com/implementation-of-semi-supervised-generative-adversarial-networks-in-keras-195a1b2c3ea6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scuHrD98ZD7U"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Conv2DTranspose,Input,Reshape,Activation,Lambda\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import BatchNormalization,Dropout,Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        " \n",
        "img_shape = (img_rows,img_cols,channels)\n",
        " \n",
        "z_dim = 100\n",
        "num_classes = 10"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "Y4UIt0-1aBGP",
        "outputId": "c8536791-284e-4da6-d05f-7c976ce1b52a"
      },
      "source": [
        "class Dataset:\n",
        "  def __init__(self,num_labeled,num_classes):\n",
        "    self.num_labeled = num_labeled\n",
        "    self.num_classes = num_classes\n",
        "    (self.x_train,self.y_train),(self.x_test,self.y_test) = mnist.load_data()      #loading mnist data\n",
        "  \n",
        "    def preprocess_image(x):\n",
        "      x = (x.astype(np.float32)-127.5)/127.5      #preprocessing images to [-1,1] \n",
        "      x = np.expand_dims(x,axis=-1)\n",
        "      return x\n",
        "  \n",
        "    def preprocess_labels(y):\n",
        "      return y.reshape((-1,1))\n",
        "\n",
        "    self.x_train = preprocess_image(self.x_train)\n",
        "    print(np.min(self.x_train))\n",
        "    self.y_train = preprocess_labels(self.y_train)\n",
        "    self.x_test = preprocess_image(self.x_test)\n",
        "    self.y_test = preprocess_labels(self.y_test)\n",
        " \n",
        "  def batch_labeled(self,batch_size):\n",
        " \n",
        "    sample_per_class = int(self.num_labeled/self.num_classes)\n",
        "    imgs = list()\n",
        "    labels = list()\n",
        "    for i in range(sample_per_class):\n",
        "      idx = self.y_train==i                             #getting indexes where y_train == i\n",
        "      idx = [i for i, x in enumerate(idx) if x]\n",
        "      x_classes= self.x_train[idx]\n",
        "      y_classes = self.y_train[idx]\n",
        "      #index = np.random.randint(0,x_classes.shape[0],sample_per_class)\n",
        "      index = np.arange(sample_per_class)\n",
        "      x_imgs = x_classes[index]                #taking 10 samples from the specific label \n",
        "      y_imgs = y_classes[index]\n",
        "      \n",
        "      #print(x_imgs.shape)\n",
        "      [imgs.append(x_imgs[j]) for j in index ]\n",
        "      [labels.append(y_imgs[j]) for j in range(num_classes)]\n",
        " \n",
        "    imgs = np.asarray(imgs)\n",
        "    labels = np.asarray(labels)\n",
        "    #print(labels)\n",
        " \n",
        "    ix  = np.random.randint(0,self.num_labeled,batch_size)\n",
        "    imgs = imgs[ix]\n",
        "    labels = labels[ix]\n",
        "    #print(labels.shape)\n",
        "    return imgs,labels\n",
        " \n",
        "  def batch_unlabeled(self,batch_size):\n",
        "    idx = np.random.randint(self.num_labeled,self.x_train.shape[0],batch_size)\n",
        "    imgs = self.x_train[idx]\n",
        "    return imgs\n",
        " \n",
        "  def training_set(self):\n",
        "     x_train = self.x_train[range(self.num_labeled)]  \n",
        "     y_train = self.y_train[range(self.num_labeled)]\n",
        "     return x_train ,y_train\n",
        "  def testing_set(self):\n",
        "    return self.x_test,self.y_test\n",
        " \n",
        "num_labeled = 100\n",
        "num_classes = 10\n",
        "dataset = Dataset(num_labeled,num_classes)\n",
        "i= dataset.batch_unlabeled(32)\n",
        "plt.imshow(i[0,:,:,0],cmap='gray')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "-1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f036f9968d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atgvA2BAamBj"
      },
      "source": [
        "def build_generator(z_dim):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256*7*7,input_dim=z_dim))\n",
        "  model.add(Reshape((7,7,256)))\n",
        "  model.add(Conv2DTranspose(128,kernel_size=3,strides=2,padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(alpha=0.01))\n",
        "  model.add(Conv2DTranspose(64,kernel_size=3,strides=1,padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(alpha=0.01))\n",
        "  model.add(Conv2DTranspose(1,kernel_size=(3,3),strides=2,padding='same',activation='tanh'))\n",
        "  ## using tanh activation gives better images\n",
        "\n",
        "  return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op1Zg6YDbCwN",
        "outputId": "046a4482-8854-48fd-dc0e-3aada9c5029c"
      },
      "source": [
        "build_generator(100).summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12544)             1266944   \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 14, 14, 128)      295040    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 14, 14, 128)      512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       73792     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        577       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,637,121\n",
            "Trainable params: 1,636,737\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp-pSf2fbHgs"
      },
      "source": [
        "def build_discriminator(img_shape):\n",
        "  inp = Input(shape=img_shape)\n",
        "\n",
        "  X = Conv2D(32,kernel_size=(3,3),strides=2,input_shape=img_shape,padding='same')(inp)\n",
        "  X = LeakyReLU(alpha=0.01)(X)\n",
        "  X = Conv2D(64,kernel_size=(3,3),strides=2,padding='same')(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = LeakyReLU(alpha=0.01)(X)\n",
        "  X = Conv2D(128,kernel_size=(3,3),strides=2,padding='same')(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = LeakyReLU(alpha=0.01)(X)\n",
        "\n",
        "  \n",
        "  X = Flatten(name=\"flatten\")(X)\n",
        "  X = Dropout(0.5)(X)\n",
        "  X = Dense(num_classes)(X)\n",
        "  model = Model(inputs=inp,outputs=X)\n",
        "  return model\n",
        "\n",
        "  def build_discriminator_supervised(discriminator):\n",
        "    model = Sequential()\n",
        "    model.add(discriminator)\n",
        "    model.add(Activation('softmax'))\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgN4EWD0bdQZ"
      },
      "source": [
        "def build_discriminator_supervised(discriminator):\n",
        "  model = Sequential()\n",
        "  model.add(discriminator)\n",
        "  model.add(Activation('softmax'))\n",
        "  return model\n",
        "\n",
        "\n",
        "def build_discriminator_unsupervised(discriminator):\n",
        "  model = Sequential()\n",
        "  model.add(discriminator)\n",
        "  def custom_activation(x):\n",
        "        \n",
        "    prediction = 1.0 - (1.0 /\n",
        "                           (K.sum(K.exp(x), axis=-1, keepdims=True) + 1.0))\n",
        "    return prediction\n",
        "  model.add(Lambda(custom_activation))\n",
        "  \n",
        "  return model\n",
        "\n",
        "def build_gan(generator,discriminator):\n",
        "  model = Sequential()\n",
        "  model.add(generator)\n",
        "  model.add(discriminator)\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_NH8UQqcdi3"
      },
      "source": [
        "discriminator = build_discriminator(img_shape)\n",
        "discriminator_supervised = build_discriminator_supervised(discriminator)\n",
        "discriminator_supervised.compile(optimizer= Adam(learning_rate=0.001),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
        "discriminator_unsupervised = build_discriminator_unsupervised(discriminator)\n",
        "discriminator_unsupervised.compile(optimizer = Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "generator = build_generator(z_dim)\n",
        "discriminator_unsupervised.trainable = False\n",
        "gan = build_gan(generator,discriminator_unsupervised)\n",
        "gan.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWSHtMDkdSyF"
      },
      "source": [
        "supervised_losses = []\n",
        "iteration_checkpoints = []\n",
        "accuracies = []\n",
        "val_losses = []\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "x_test,y_test = dataset.testing_set()\n",
        "y_test = to_categorical(y_test,num_classes)\n",
        "\n",
        "def train(iterations,batch_size,sample_interval):\n",
        "\n",
        "  real = np.ones((batch_size,1))\n",
        "  fake = np.zeros((batch_size,1))\n",
        "\n",
        "  for iteration in range(iterations):\n",
        "    imgs,labels = dataset.batch_labeled(batch_size)\n",
        "    \n",
        "    #print(labels)\n",
        "    labels = to_categorical(labels,num_classes=num_classes)\n",
        "\n",
        "    unlabeled_imgs = dataset.batch_unlabeled(batch_size)\n",
        "\n",
        "    z = np.random.normal(0,1,(batch_size,z_dim))\n",
        "    \n",
        "    fake_imgs = generator.predict(z)\n",
        "    #print(fake_imgs.shape)\n",
        "\n",
        "    d_supervised_loss,accuracy = discriminator_supervised.train_on_batch(imgs,labels)\n",
        "    d_unsupervised_loss_real = discriminator_unsupervised.train_on_batch(unlabeled_imgs,real)\n",
        "    d_unsupervised_loss_fake = discriminator_unsupervised.train_on_batch(fake_imgs,fake)\n",
        "    d_unsupervised_loss = 0.5*np.add(d_unsupervised_loss_real,d_unsupervised_loss_fake)\n",
        "\n",
        "    z = np.random.normal(0,1,(batch_size,z_dim))\n",
        "    fake_imgs = generator.predict(z)\n",
        "    generator_loss = gan.train_on_batch(z,real)\n",
        "\n",
        "    \n",
        "    if(iteration+1) % sample_interval ==0:\n",
        "      supervised_losses.append(d_supervised_loss)\n",
        "      accuracies.append(100*accuracy)\n",
        "      iteration_checkpoints.append(iteration+1)\n",
        "      val_loss = discriminator_supervised.evaluate(x=x_test,y=y_test,verbose=0)\n",
        "      val_losses.append(val_loss[0])\n",
        "      print(\"Iteration No.:\",iteration+1,end=\",\")\n",
        "      print(\"Discriminator Supervised Loss:\",d_supervised_loss,end=',')\n",
        "      print('Generator Loss:',generator_loss,end=\",\")\n",
        "      print('Discriminator Unsuperived Loss:',d_unsupervised_loss,sep=',')\n",
        "      print('val_loss:',val_loss,sep=',')\n",
        "      print('Accuracy Supervised:',100*accuracy)\n",
        "      #sample_images(generator)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmoDJdXNeFaL",
        "outputId": "074ca2ba-3da8-4055-85ca-2c4c4d70932f"
      },
      "source": [
        "iterations = 6000\n",
        "batch_size = 32\n",
        "sample_interval = 100\n",
        "train(iterations,batch_size,sample_interval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No.: 100,Discriminator Supervised Loss: 0.002665058709681034,Generator Loss: [0.052548736333847046, 1.0],Discriminator Unsuperived Loss:,[6.79806035e-04 1.00000000e+00]\n",
            "val_loss:,[1.190253734588623, 0.6676999926567078]\n",
            "Accuracy Supervised: 100.0\n"
          ]
        }
      ]
    }
  ]
}